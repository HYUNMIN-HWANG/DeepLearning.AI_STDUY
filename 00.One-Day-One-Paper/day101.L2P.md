# Learning to Prompt for Continual Learning

![image](https://user-images.githubusercontent.com/70581043/176661864-1335bff6-7335-456b-9b8b-83d0318563b8.png)
### L2P
 - orthogonal to popular rehearsal-based methods and applicable to practical continual learning scenarios without known task identity or boundaries
 - L2P keeps the pre-trained model untouched
 - learns a set of prompts that dynamically instruct models to solve corresponding tasks. 
 - prompt pool (a key-value shared meomory space)
 - design a query mechanism to dynamically lookup a subset of task-relevant prompts based on the instance-wise input features
 - leading to minimal catastrophic forgetting without the necessity of a rehearsal buffer.