CLIP와 CoOp의 한계점을 극복한 ProGrad 모델을 제안했다.
- 기존 모델의 한계점 : 
    - prompt 를 hand-crafted 튜닝을 하면 시간이 많이 걸린다. 어떤게 좋은 성능을 보이는 지 알수가 없다.
    - 특정 domain에 특화된 task를 수행할 수 있다.
    - train을 할 수록 generalization ability가 떨어진다. 
    - GradCAM으로 확인할 때도,  forget general knowledge한다는 게 보인다. foreground object 에 덜 focus 한다.

## Prompt-aligned Gradient for Prompt Tuning (ProGrad)
각 training step을 general knowledge와 충돌하지 않는 방향으로 regularize 한다. 
- G_KL : gradient of Kullback–Leibler (KL) divergence between the predictions of the zero-shot prompted CLIP and the few-shot fine-tuned model,
- G_ce : gradient of cross-entropy between the groundtruth and the few-shot fine-tuned model, dubbed domain-specific direction
    -  orthogonal to the general direction 한 방향과
    - vector parallel to the general direction 방향으로 분리할 수 있다.

![image](https://user-images.githubusercontent.com/70581043/186422572-187e2f1c-394a-455c-b633-c436c1e0ab43.png)
- cross-entropy : 
![image](https://user-images.githubusercontent.com/70581043/186422659-8ce143b1-a60f-418c-8163-df66b30ebef8.png)
- general knowledge direction based on the Kullback-Leibler (KL) divergence : 
![image](https://user-images.githubusercontent.com/70581043/186423005-402676ec-6051-4fe4-94be-9a0d1f220c33.png)
- G_KL 와 G_ce 사이 각도가 90도일 때, G_ce 방향으로 prograd
- G_KL 와 G_ce 사이 각도가 90도 보다 클 때, G_KL 와 수직인 방향으로 prograd

### Restults
![image](https://user-images.githubusercontent.com/70581043/186423793-88ca1b5a-79bf-48a9-9ba1-8b7dd095b2ba.png)
ProGrad outperforms CoOp by 9:5%, 6:9% and 5:1% on FGVCAircraft, EuroSAT and Flowers102 given 1 shot, and the average improvement over 11 datasets is 3:2%

![image](https://user-images.githubusercontent.com/70581043/186423985-5c03746d-8e63-4299-b9f8-94fc28bb6ee1.png)
CoOp는 unseen classes를 일반화하지 못했다. 하지만 ProGrad는 새로운  class도 일반화할 수 있었다.