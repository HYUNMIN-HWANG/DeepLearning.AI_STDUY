domain의 변화에 따라 변화하지 않는 featrue를 뽑기는 어렵다. 게다가 이를 한꺼번에 fully incoporate 하는 것도 쉽지 않음,     

따라서 해당 논문은 1. 각기 다른 domain knoledge를 임베딩하는 서로 다른 domain prompts를 만들기 2. domain adapter (input iamge와 source image간의 distance분석)을 함으로써 domain generalizable model을 만들고자 함

## DoPrompt = Domain Prompt Learning (DPL) + Prompt Adapter Learning (PAL)
![image](https://user-images.githubusercontent.com/70581043/187191224-de6c5ce9-8835-409e-bf05-ce57380cf107.png)

### Domain Prompt Learning (DPL)
- the domain prompts to carry the domain-specific knowledge
- Promot = K개의 source domain의 모음
![image](https://user-images.githubusercontent.com/70581043/187196055-396355aa-a15e-43f8-ae1f-50241744e70b.png)
- [CSL] = [CLS] 토큰 + 이미지 패치 단위로 자른 거 + prompt
![image](https://user-images.githubusercontent.com/70581043/187196157-5938f5e0-e777-48e8-a4ef-f9ebfdd5b5cf.png)
- training loss
![image](https://user-images.githubusercontent.com/70581043/187196266-584ad54c-2fa4-4e80-b2fd-451dfe183e97.png)

### Inference and Prompt Adapter Learning
- for prediction on unseen target domains
- source domain에서 학습한 지식을 target domain까지 확장하고자 함
![image](https://user-images.githubusercontent.com/70581043/187196476-54222250-f639-46a0-9346-a1dd8222e5ea.png)
- A : Adapter : two-layer MLP with softmax layer
- w : linear combination weight, 
- Inference
![image](https://user-images.githubusercontent.com/70581043/187197652-03ec5f86-a37b-4c1e-9149-aa3bf733634e.png)
- Loss
   - domain promt에 맞는 것은 1, 그 외의 것은 0 
![image](https://user-images.githubusercontent.com/70581043/187197709-76f3af68-127a-4387-9f3a-1de7acffb42f.png)
   - generate prompt ; 마지막에 제대로된 이미지를 예측하는데 기여한 prompt
![image](https://user-images.githubusercontent.com/70581043/187198623-7dc62ab1-6341-4123-a5ea-ec1017430c24.png)
